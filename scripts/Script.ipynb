{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add early stop // explain it as well\n",
    "Move visualizations up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyTorch Libraries for Neural Network\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.model_selection import train_test_split    # Scikit-Lean for preparing the train-test data split\n",
    "\n",
    "# Pandas for reading data in .csv format \n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Plotting tools\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import numpy as np\n",
    "import plotly.graph_objs as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_visualization(data, duration, randomseed=False, output=False):\n",
    "    if output is True:\n",
    "        dim1, dim2, dim3 = data[:,0], data[:,1], data[:,2]\n",
    "    else:\n",
    "        dim1, dim2, dim3 = np.array(data['hand_orig_rua_x']), np.array(data['hand_orig_rua_y']), np.array(data['hand_orig_rua_z'])\n",
    "\n",
    "    if duration is not None:\n",
    "        if randomseed:\n",
    "            np.random.seed(42)\n",
    "        else: \n",
    "            np.random.seed(None)\n",
    "        reduced_samples = 10 * duration\n",
    "        start_index = np.random.choice(len(dim1) - reduced_samples + 1)\n",
    "        dim1 = dim1[start_index : start_index + reduced_samples]\n",
    "        dim2 = dim2[start_index : start_index + reduced_samples]\n",
    "        dim3 = dim3[start_index : start_index + reduced_samples]\n",
    "        \n",
    "    return dim1, dim2, dim3\n",
    "\n",
    "def pltshow(x_lable, y_label, title, legend = False):\n",
    "    \n",
    "    plt.xlabel(x_lable)\n",
    "    plt.ylabel(y_label)\n",
    "    plt.title(title)\n",
    "    if legend == True:\n",
    "        plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "def output_visualization(data, duration=None, randomseed=False):\n",
    "    dim1, dim2, dim3 = data_visualization(data, duration, randomseed)\n",
    "\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    ax.scatter(dim1, dim2, dim3, c='b', marker='o')\n",
    "\n",
    "    ax.set_xlabel('X-Dimension')\n",
    "    ax.set_ylabel('Y-Dimension')\n",
    "    ax.set_zlabel('Z-Dimension')\n",
    "    ax.set_title('Predicted Values in 3D Space')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "def interactive_output_visualization(data, duration=None, randomseed=False, output=False, output_data = None):\n",
    "    dim1, dim2, dim3 = data_visualization(data, duration, randomseed, output)\n",
    "    \n",
    "    trace = go.Scatter3d(x=dim1, y=dim2, z=dim3, mode='markers', marker=dict(size=3, \n",
    "                                                                             color='blue', \n",
    "                                                                             opacity=0.8),\n",
    "                                                                             name=\"Input Points\")\n",
    "\n",
    "    if output:\n",
    "        dim1, dim2, dim3 = data_visualization(output_data, duration, randomseed, output)\n",
    "        trace_output = go.Scatter3d(x=dim1, y=dim2, z=dim3, mode='markers', marker=dict(size=3, \n",
    "                                                                                    color='red', \n",
    "                                                                                    opacity=0.8), \n",
    "                                                                                    name='Output Points')\n",
    "        traces = [trace, trace_output]\n",
    "        title = 'Input and Output Points in 3D Space'\n",
    "    else:\n",
    "        traces = [trace]\n",
    "        title = 'Values in 3D Space'\n",
    "\n",
    "    layout = go.Layout(title=title, scene=dict(xaxis=dict(title='X-Dimension'),\n",
    "                                                                        yaxis=dict(title='Y-Dimension'),\n",
    "                                                                        zaxis=dict(title='Z-Dimension')))\n",
    "\n",
    "    fig = go.Figure(data=traces, layout=layout)\n",
    "    fig.show()\n",
    "\n",
    "def correlationPlot(data):\n",
    "    pressure_label = \"sw_pres\"  # Smart Watch Pressure\n",
    "    yPos_label = \"hand_orig_rua_y\"    # Y Hand Position\n",
    "    dim1, dim2 = np.array(data[pressure_label]), np.array(data[yPos_label])\n",
    "    dim1, dim2 = dim1[1:], dim2[1:]\n",
    "    \n",
    "    slope, intercept = np.polyfit(dim1, dim2, deg=1)\n",
    "    regression_line = slope * dim1 + intercept\n",
    "\n",
    "    mse = np.mean((dim2 - regression_line)**2)\n",
    "\n",
    "    plt.scatter(dim1, dim2, c='b', marker='.')\n",
    "    plt.plot(dim1, regression_line, c='r', label='Linear Fit')\n",
    "    pltshow(\"Smart Watch Pressure\", \"Y Hand Positon\", f\"Correlation between {pressure_label} & {yPos_label}\\nMSE: {mse: .3f}\", legend=True)\n",
    "\n",
    "def accDistPlot(data, column_name = \"sw_lacc_y\"):\n",
    "    acceleration_values = data[column_name]\n",
    "    \n",
    "    plt.plot(list(range(1, 1 + len(acceleration_values))), acceleration_values, color= 'b')\n",
    "    pltshow(\"Time\", \"Acceleration\", \"Distribution of Acceleration over Time\")\n",
    "\n",
    "    mean_acceleration = np.mean(acceleration_values)\n",
    "    std_acceleration = np.std(acceleration_values)\n",
    "    plt.hist(acceleration_values, bins='auto', density=True, alpha=0.7, color='b')\n",
    "    x = np.linspace(mean_acceleration - 3 * std_acceleration, mean_acceleration + 3 * std_acceleration, 100)\n",
    "    y = (1 / (std_acceleration * np.sqrt(2 * np.pi))) * np.exp(-0.5 * ((x - mean_acceleration) / std_acceleration) ** 2)\n",
    "    plt.plot(x, y, color='r')\n",
    "    pltshow('Acceleration', 'Density','Distribution of Acceleration Over Time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/Users/affanbinusman/Dropbox (ASU)/IRL-Lab/P&G/hackathon_data'     # Update path where your data is located\n",
    "\n",
    "# Get a list of all CSV files in the folder\n",
    "csv_files = [file for file in os.listdir(path) if file.endswith('.csv')]\n",
    "\n",
    "# Read data from each file and store it in a list\n",
    "data_list = []\n",
    "for csv_file in csv_files:\n",
    "    file_path = os.path.join(path, csv_file)\n",
    "    df = pd.read_csv(file_path)\n",
    "    data_list.append(df)\n",
    "\n",
    "# Concatenate the data from all files into a single DataFrame\n",
    "data = pd.concat(data_list, ignore_index=True) # Use the `ignore_index=True` parameter to reset the index of the concatenated DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/Users/affanbinusman/Dropbox (ASU)/IRL-Lab/P&G/hackathon_data'     # Update path where your data is located\n",
    "\n",
    "# Get a list of all CSV files in the folder\n",
    "csv_files = [file for file in os.listdir(path) if file.endswith('.csv')]\n",
    "csv_file = csv_files[0]\n",
    "# Read data from each file and store it in a list\n",
    "data_list = []\n",
    "# for csv_file in csv_files:\n",
    "file_path = os.path.join(path, csv_file)\n",
    "df = pd.read_csv(file_path)\n",
    "data_list.append(df)\n",
    "\n",
    "# Concatenate the data from all files into a single DataFrame\n",
    "data = pd.concat(data_list, ignore_index=True) # Use the `ignore_index=True` parameter to reset the index of the concatenated DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hamilton_product(a: np.array, b: np.array):\n",
    "    \"\"\"\n",
    "    Hamilton product for two quaternions or a Vec4 and a Quaternion.\n",
    "    :param a: quaternion or vec4 in order [w,x,y,z]\n",
    "    :param b: quaternion in order [w,x,y,z]\n",
    "    \"\"\"\n",
    "    # check shape to deal with a whole column of rotations\n",
    "    if len(a.shape) > 1:\n",
    "        a = [a[:, 0], a[:, 1], a[:, 2], a[:, 3]]\n",
    "    if len(b.shape) > 1:\n",
    "        b = [b[:, 0], b[:, 1], b[:, 2], b[:, 3]]\n",
    "    h_p = np.array([\n",
    "        a[0] * b[0] - a[1] * b[1] - a[2] * b[2] - a[3] * b[3],\n",
    "        a[0] * b[1] + a[1] * b[0] + a[2] * b[3] - a[3] * b[2],\n",
    "        a[0] * b[2] - a[1] * b[3] + a[2] * b[0] + a[3] * b[1],\n",
    "        a[0] * b[3] + a[1] * b[2] - a[2] * b[1] + a[3] * b[0]\n",
    "    ], dtype=np.float64)\n",
    "    if len(h_p.shape) > 1:\n",
    "        return h_p.transpose()\n",
    "    else:\n",
    "        return h_p\n",
    "    \n",
    "\n",
    "def quat_invert(q: np.array):\n",
    "    \"\"\"\n",
    "    estimates the inverse rotation.\n",
    "    :param q: input quaternion\n",
    "    :return: inverse quaternion\n",
    "    \"\"\"\n",
    "    q_s = q * np.array([1, -1, -1, -1], dtype=np.float64)  # the conjugate of the quaternion\n",
    "    if len(q.shape) > 1:\n",
    "        return q_s / np.sum(np.square(q, dtype=np.float64), axis=1, keepdims=True, dtype=np.float64)\n",
    "    else:\n",
    "        return q_s / np.sum(np.square(q, dtype=np.float64), dtype=np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# relative watch orientation in global\n",
    "sw_quat_raw = hamilton_product(quat_invert(sw_rot_fwd), sw_rot)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_path = '/Users/affanbinusman/Dropbox (ASU)/IRL-Lab/P&G/hackathon_data/watch_phone_motive_rec_2023-07-07_17-28-44.csv'     # Update path where your data is located\n",
    "# data = pd.read_csv(file_path)\n",
    "\n",
    "# print(len(data), data.shape)\n",
    "\n",
    "duration = 40       \n",
    "output_visualization(data)\n",
    "output_visualization(data, duration=duration, randomseed=False)\n",
    "\n",
    "interactive_output_visualization(data)\n",
    "interactive_output_visualization(data, duration=duration, randomseed=False)\n",
    "\n",
    "correlationPlot(data)\n",
    "\n",
    "accDistPlot(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('sw_rotvec_w')\n",
    "accDistPlot(data, 'sw_rotvec_w')\n",
    "print('sw_gyro_x')\n",
    "accDistPlot(data, 'sw_gyro_x')\n",
    "print('sw_lvel_x')\n",
    "accDistPlot(data, 'sw_lvel_x')\n",
    "print('sw_lacc_x')\n",
    "accDistPlot(data, 'sw_lacc_x')\n",
    "print('sw_pres')\n",
    "accDistPlot(data, 'sw_pres')\n",
    "print('sw_lacc_x')\n",
    "accDistPlot(data, 'sw_lacc_x')\n",
    "print('sw_grav_x')\n",
    "accDistPlot(data, 'sw_grav_x')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing libraries "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Architecture & Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Data Loader: \n",
    "        This serves as the framework to load data using pandas and segment out the useful columns (labels and inputs)\n",
    "\"\"\"\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    def __init__ (self, data):\n",
    "        self.data = data\n",
    "        self.features = self.data.iloc[:, 27:44].values     # All smart watch inputs that contribute towards the outputs\n",
    "        self.labels = self.data.iloc[:, 4:7].values          # The model predicts X, Y, Z coordinates of hand\n",
    "\n",
    "    def __len__ (self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__ (self, idx):\n",
    "        features = torch.tensor(self.features[idx], dtype=torch.float32) \n",
    "        label = torch.tensor(self.labels[idx], dtype=torch.float32)\n",
    "        return features, label\n",
    "    \n",
    "\"\"\"\n",
    "    Neural Network / Model:\n",
    "        A simple linear architecture based model with 3 layers (including input and output layers). \n",
    "        The layer dimensions are: 17 - 128 - 3\n",
    "\"\"\"\n",
    "\n",
    "class MyModel(nn.Module):\n",
    "    def __init__ (self, input_size, hidden_size, output_size):\n",
    "        super (MyModel, self).__init__()\n",
    "        \n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
    "        self.relu = nn.LeakyReLU()\n",
    "        \n",
    "        # self.fc1 = nn.Linear(input_size, hidden_size + int(hidden_size/3))\n",
    "        # self.fc2 = nn.Linear(hidden_size + int(hidden_size/3), hidden_size - int(hidden_size/3))\n",
    "        # self.fc3 = nn.Linear(hidden_size - int(hidden_size/3), output_size)\n",
    "        # self.relu = nn.ReLU()\n",
    "        \n",
    "        # self.fc1 = nn.Linear(input_size, 256)\n",
    "        # self.fc2 = nn.Linear(256, 64)\n",
    "        # self.fc3 = nn.Linear(64, 16)\n",
    "        # self.fc3 = nn.Linear(32, 16)\n",
    "        # self.fc3 = nn.Linear(16, 8)\n",
    "        # self.fc3 = nn.Linear(8, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    We encourage you to play around with these parameters to see what works better for this model architecture and dataset.\n",
    "\"\"\"\n",
    "batch_size = 500        \n",
    "learning_rate = 0.0005\n",
    "num_epochs = 100\n",
    "test_data_size = 0.2            # Range 0-1. You may increase or decrease the recommended testing data size by updating this variable\n",
    "\n",
    "hidden_size = 256                # This represents the middle layer of the neural network. You may manually play around with the model architecture by adding more layers\n",
    "criterion = nn.SmoothL1Loss()   # Try out different loss functions and optimizers to see what works with different tasks. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data loading calls to class and functions\n",
    "dataset = MyDataset(data)\n",
    "\n",
    "train_dataset, test_dataset = train_test_split(dataset, test_size=test_data_size, shuffle=True)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Initialzing the model with inputs\n",
    "input_size = len(dataset.features[0])\n",
    "output_size = len(dataset.labels[0])\n",
    "\n",
    "model = MyModel(input_size, hidden_size, output_size)\n",
    "criterion = nn.SmoothL1Loss() #mean square / regression\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)        # For more information, visit: https://pytorch.org/docs/stable/nn.html#loss-functions, https://pytorch.org/docs/stable/optim.html\n",
    "\n",
    "\"\"\"\n",
    "    If you have GPU resource available, the training process will be faster!\n",
    "    It's okay if you dont have a GPU. The code works without one as well. \n",
    "\"\"\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For visually observing the losses\n",
    "losses = {\"training\" : [], \n",
    "          \"evaluation\" : [], \n",
    "          \"labels\" : [], \n",
    "          \"outputs\" : [],\n",
    "          \"labels_t\" : [], \n",
    "          \"outputs_t\" : []\n",
    "          }\n",
    "\n",
    "# Training & Evaluation Porcess\n",
    "patience = 50\n",
    "best_loss = float('inf')\n",
    "num_epochs_without_improvement = 0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    all_outputs_training = []\n",
    "    all_labels_training = []\n",
    "    # Training Process\n",
    "    model.train(True)\n",
    "    running_loss = 0.0                          # To calculates the losses in training for each epoch\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs = inputs.to(device)              # Transfers data to GPU/CPU\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()                   # Zeros the optimizer before generating output\n",
    "        outputs = model(inputs)                 # Calculates the output\n",
    "        loss = criterion(outputs, labels)       # Finds loss as per the criteria defined\n",
    "        loss.backward()                         # Back propogation of loss\n",
    "        optimizer.step()                        # Updates parameters based on gradients computed duing back propogation\n",
    "        \n",
    "\n",
    "        # print(loss)\n",
    "        running_loss += loss.item()             # Calculates loss over the training\n",
    "\n",
    "        all_outputs_training.append(outputs.detach().numpy())  # Append outputs to the list\n",
    "        all_labels_training.append(labels.detach().numpy())    # Append labels to the list\n",
    "    \n",
    "    training_loss = running_loss/len(train_loader)\n",
    "    # print(len(train_loader))\n",
    "\n",
    "    \"\"\"\n",
    "    Evaluating the model that has been trained (so far). \n",
    "    You would notice similar steps as during the training process. The lack of a few lines of code is because we \n",
    "    are evaluating the model here and not training it.\n",
    "    \"\"\"\n",
    "    model.train(False)\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    all_outputs = []\n",
    "    all_labels = []\n",
    "\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            all_outputs.append(outputs.cpu().numpy())  # Append outputs to the list\n",
    "            all_labels.append(labels.cpu().numpy())    # Append labels to the list\n",
    "                \n",
    "    mean_loss = total_loss / len(test_loader)\n",
    "\n",
    "    if mean_loss < best_loss:\n",
    "        best_loss = mean_loss\n",
    "        num_epochs_without_improvement = 0\n",
    "    else:\n",
    "        num_epochs_without_improvement += 1\n",
    "        if num_epochs_without_improvement == patience:\n",
    "            print(\"Early stopping triggered. Stopping training.\")\n",
    "            break\n",
    "    \n",
    "    losses[\"training\"].append(training_loss)\n",
    "    losses[\"evaluation\"].append(mean_loss)\n",
    "    losses[\"outputs\"] = np.concatenate(all_outputs)\n",
    "    losses[\"labels\"] = np.concatenate(all_labels)\n",
    "    \n",
    "    losses[\"outputs_t\"] = np.concatenate(all_outputs_training)\n",
    "    losses[\"labels_t\"] = np.concatenate(all_labels_training)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Training Loss: {training_loss}, Smooth L1 Loss: {mean_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_total = range(1, 1 + len(losses[\"evaluation\"]))\n",
    "\n",
    "plt.subplots(1, figsize=(20,5))\n",
    "plt.plot(epochs_total, losses[\"training\"], label = \"Training Loss\")\n",
    "plt.plot(epochs_total, losses[\"evaluation\"], label = \"Evaluation Loss\")\n",
    "pltshow('Epochs', 'Loss', 'Losses over Epochs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "put a 3d display of outputs with original values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(losses[\"labels\"].shape, losses[\"outputs\"].shape, losses[\"labels_t\"].shape, losses[\"outputs_t\"].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses[\"outputs_t\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses[\"labels_t\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "losses[\"outputs\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactive_output_visualization(losses[\"labels\"], duration=2, randomseed=False, output=True, output_data=losses[\"outputs\"])\n",
    "print()\n",
    "\n",
    "interactive_output_visualization(losses[\"labels_t\"], duration=None, randomseed=False, output=True, output_data=losses[\"outputs_t\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "correlation plots / pressure & y-pos hand\n",
    "3d visualization of ground truth\n",
    "distrubution of accelaration"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
