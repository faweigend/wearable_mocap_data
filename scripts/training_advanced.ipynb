{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pose Prediction From Smartwatch Data\n",
    "### Part 3\n",
    "\n",
    "Welcome! This notebook is the second chapter of the hackathon challenge to predict human arm pose from the sensor data of a single smartwatch. In other words, a human wears a smartwatch, and we will try to predict their arm pose from the sensor outputs we can read from the watch.\n",
    "\n",
    "## Creating a Predictive Model with Machine Learning\n",
    "\n",
    "In this second chapter, we will have the opportunity to utilize the processed data from the previous chapter and train a Neural Network to generate predictions. The following sections will guide you step-by-step through model architecture design, model training and evaluation, performance analysis, and 3D visualization for better interpretability of the model's performance. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Downloading Dependencies (Optional)\n",
    "\n",
    "We begin by downloading the libraries in this notebook. If you have all of these pre-installed, you may skip this step.\n",
    "\n",
    "Note: We installed some packages in the first notebook. If you skipped running it, please run step 0 from the first notebook to download dependacies and continute with this notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: torch in /Users/affanbinusman/Library/Python/3.9/lib/python/site-packages (2.0.1)\n",
      "Requirement already satisfied: filelock in /Users/affanbinusman/Library/Python/3.9/lib/python/site-packages (from torch) (3.8.0)\n",
      "Requirement already satisfied: typing-extensions in /Users/affanbinusman/Library/Python/3.9/lib/python/site-packages (from torch) (4.5.0)\n",
      "Requirement already satisfied: sympy in /Users/affanbinusman/Library/Python/3.9/lib/python/site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in /Users/affanbinusman/Library/Python/3.9/lib/python/site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in /Users/affanbinusman/Library/Python/3.9/lib/python/site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/affanbinusman/Library/Python/3.9/lib/python/site-packages (from jinja2->torch) (2.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/affanbinusman/Library/Python/3.9/lib/python/site-packages (from sympy->torch) (1.3.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip\u001b[0m\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: sklearn in /Users/affanbinusman/Library/Python/3.9/lib/python/site-packages (0.0.post1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install torch\n",
    "!pip install sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Importing Libraries\n",
    "\n",
    "Lets import the libraries we will be primarily working with in this notebook. You may notice some similar ones. Let us help you understand why:\n",
    "- Libraries like Numpy and Pandas are helpful for mathematical functions and data frameworks respectively. Therefore, you would see them almost everywhere.\n",
    "- Matplotlib is often used to display plots. Using plotly, we will display interactive plots. But why do we need plots for training a machine learning model? You will find out soon. \n",
    "- Finally, Torch (PyTorch) provides powerful tools to deploy Neural Networks (NN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyTorch Libraries for Neural Network\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.model_selection import train_test_split    # Scikit-Lean for preparing the train-test data split\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Plotting tools\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "# adjust data paths in config.py\n",
    "import config   \n",
    "import os    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Loading Processed Data\n",
    "\n",
    "Let's load the normalized dataset into the environment that we processed in the previous notebook. You will notice two files in the cache folder. \n",
    "1. `normalized_data.csv` contains the normalized dataset\n",
    "2. `means_stds.csv` contains the means and standard deviations of different columns utilized during normalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cache_path = config.paths[\"cache_path\"]\n",
    "path = os.path.join(cache_path, \"normalized_data.csv\")\n",
    "data_normalized = pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Plotting Functions\n",
    "Lets get the simpler stuff out of the way first. Since the neural networks will help estimate the X, Y & Z coordinates, we use a similar 3D visualization for representing the outputs by the model and actual labels to gain a deeper understanding of model's performance. \n",
    "\n",
    "Secondly, during the training process you will notice the loss decreases with epochs. It is useful to visualize the loss for a number of reasons:\n",
    "- Overfitting: When model starts remembering the training dataset instead of figuring out a \"pattern\".\n",
    "- Performance: To figure out if further training decreases or increases loss \n",
    "\n",
    "Note: Epoch refers to the iteration number where the model goes through the entire training data. For instance, 1 epoch indicates that model has passed through the data once. \n",
    "\n",
    "For these purposes, we are using helper functions that can be called repeatedly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    This section represents the function and helper function required for interactive 3D visualization:\n",
    "        - The interactive_output_visualization function helps in visualizing the X, Y, Z coordinates in an interactive 3D map. It is also used to display the output and original labels\n",
    "\"\"\"\n",
    "\n",
    "# Helper function that provides appropriate the approriate length for columns. \n",
    "# The duration variable helps in defining the length of continuous data - this helps in visualizing a smaller hand trajectory \n",
    "# The randomseed variable helps to visualize the same data without randomizing the selection process\n",
    "# The remaining functions follow the same variables and analogy\n",
    "def data_visualization(data, duration, randomseed=False, output=False):\n",
    "    if output is True:\n",
    "        dim1, dim2, dim3 = data[:,0], data[:,1], data[:,2]\n",
    "    else:\n",
    "        dim1, dim2, dim3 = np.array(data['gt_hand_orig_rua_x']), np.array(data['gt_hand_orig_rua_y']), np.array(data['gt_hand_orig_rua_z'])\n",
    "\n",
    "    if duration is not None:\n",
    "        if randomseed:\n",
    "            np.random.seed(42)\n",
    "        else: \n",
    "            np.random.seed(None)\n",
    "        reduced_samples = 10 * duration\n",
    "        start_index = np.random.choice(len(dim1) - reduced_samples + 1)\n",
    "        dim1 = dim1[start_index : start_index + reduced_samples]\n",
    "        dim2 = dim2[start_index : start_index + reduced_samples]\n",
    "        dim3 = dim3[start_index : start_index + reduced_samples]\n",
    "        \n",
    "    return dim1, dim2, dim3\n",
    "\n",
    "def interactive_output_visualization(data, duration=None, randomseed=False, output=False, output_data = None):\n",
    "    dim1, dim2, dim3 = data_visualization(data, duration, randomseed, output)\n",
    "    \n",
    "    trace = go.Scatter3d(x=dim1, y=dim2, z=dim3, mode='markers', marker=dict(size=3, \n",
    "                                                                             color='blue', \n",
    "                                                                             opacity=0.8),\n",
    "                                                                             name=\"Input Points\")\n",
    "\n",
    "    if output:\n",
    "        dim1, dim2, dim3 = data_visualization(output_data, duration, randomseed, output)\n",
    "        trace_output = go.Scatter3d(x=dim1, y=dim2, z=dim3, mode='markers', marker=dict(size=3, \n",
    "                                                                                    color='red', \n",
    "                                                                                    opacity=0.5), \n",
    "                                                                                    name='Output Points')\n",
    "        traces = [trace, trace_output]\n",
    "        title = 'Input and Output Points in 3D Space'\n",
    "    else:\n",
    "        traces = [trace]\n",
    "        title = 'Values in 3D Space'\n",
    "\n",
    "    layout = go.Layout(title=title, scene=dict(xaxis=dict(title='X-Dimension'),\n",
    "                                                                        yaxis=dict(title='Y-Dimension'),\n",
    "                                                                        zaxis=dict(title='Z-Dimension')))\n",
    "\n",
    "    fig = go.Figure(data=traces, layout=layout)\n",
    "    fig.show()\n",
    "\n",
    "def lossPlot(losses):\n",
    "    epochs_total = range(1, 1 + len(losses[\"evaluation\"]))\n",
    "\n",
    "    plt.subplots(1, figsize=(20,5))\n",
    "    plt.plot(epochs_total, losses[\"training\"], label = \"Training Loss\")\n",
    "    plt.plot(epochs_total, losses[\"evaluation\"], label = \"Evaluation Loss\")\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Losses over Epochs')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Data Loader & Model Architecture\n",
    "\n",
    "A data loader is an integral part of training a neural network. The data loader assists in selecting the relevant columns assigned as features and labels. We accomplish this task using the PyTorch library. \n",
    "\n",
    "In the next portion of the code block, we implement a basic feed-forward architecture comprising an input, two hidden, and an output layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Data Loader: \n",
    "        This serves as the framework to load data using pandas and segment out the useful columns (labels and inputs)\n",
    "\"\"\"\n",
    "gt_columns = [\n",
    "    \"gt_hand_orig_rua_x\", \"gt_hand_orig_rua_y\", \"gt_hand_orig_rua_z\",\n",
    "    \"gt_larm_6drr_rh_1\", \"gt_larm_6drr_rh_2\", \"gt_larm_6drr_rh_3\",\n",
    "    \"gt_larm_6drr_rh_4\", \"gt_larm_6drr_rh_5\", \"gt_larm_6drr_rh_6\",\n",
    "    \"gt_larm_orig_rua_x\", \"gt_larm_orig_rua_y\", \"gt_larm_orig_rua_z\",\n",
    "    \"gt_uarm_6drr_rh_1\", \"gt_uarm_6drr_rh_2\", \"gt_uarm_6drr_rh_3\",\n",
    "    \"gt_uarm_6drr_rh_4\", \"gt_uarm_6drr_rh_5\", \"gt_uarm_6drr_rh_6\"\n",
    "]\n",
    "\n",
    "sw_columns = [\n",
    "    \"sw_dt\",\n",
    "    \"sw_gyro_x\", \"sw_gyro_y\", \"sw_gyro_z\",\n",
    "    \"sw_lvel_x\", \"sw_lvel_y\", \"sw_lvel_z\",\n",
    "    \"sw_lacc_x\", \"sw_lacc_y\", \"sw_lacc_z\",\n",
    "    \"sw_grav_x\", \"sw_grav_y\", \"sw_grav_z\",\n",
    "    \"sw_6drr_cal_1\", \"sw_6drr_cal_2\", \"sw_6drr_cal_3\",\n",
    "    \"sw_6drr_cal_4\", \"sw_6drr_cal_5\", \"sw_6drr_cal_6\",\n",
    "    \"sw_pres_cal\"\n",
    "]\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    def __init__ (self, data):\n",
    "        self.data = data\n",
    "        self.features = self.data.loc[:, sw_columns].values     # All smart watch inputs that contribute towards the outputs\n",
    "        self.labels = self.data.loc[:, gt_columns[0:3]].values          # The model predicts X, Y, Z coordinates of hand\n",
    "\n",
    "    def __len__ (self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__ (self, idx):\n",
    "        features = torch.tensor(self.features[idx], dtype=torch.float32) \n",
    "        label = torch.tensor(self.labels[idx], dtype=torch.float32)\n",
    "        return features, label\n",
    "    \n",
    "\"\"\"\n",
    "    Neural Network / Model:\n",
    "        A simple linear architecture based model with 3 layers (including input and output layers). \n",
    "\"\"\"\n",
    "\n",
    "class MyModel(nn.Module):\n",
    "    def __init__ (self, input_size, hidden_size, output_size, batch_size):\n",
    "        super (MyModel, self).__init__()\n",
    "        self.conv1_1 = nn.Conv1d(in_channels=input_size, out_channels= int(input_size/2), kernel_size=3, stride=1)\n",
    "        self.maxpool = nn.MaxPool1d(kernel_size=2)\n",
    "    \n",
    "        self.flattened_size = self.calculate_flattened_size(input_size)\n",
    "\n",
    "        self.fc1 = nn.Linear(self.flattened_size, hidden_size + int(hidden_size/2))\n",
    "        self.fc2 = nn.Linear(hidden_size + int(hidden_size/2), hidden_size - int(hidden_size/2))\n",
    "        self.fc3 = nn.Linear(hidden_size - int(hidden_size/2), output_size)\n",
    "        self.relu = nn.LeakyReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1_1(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        \n",
    "        print(\"shape: \", x.shape)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "    def calculate_flattened_size(self, input_size):\n",
    "        conv1_output_size = int(input_size / 2)\n",
    "        maxpool_output_size = conv1_output_size // 2\n",
    "        flattened_size = maxpool_output_size\n",
    "        return flattened_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next code block provides a basic overview of some of the tunable parameters. We encourage you to play around with these parameters to see what works better for this model architecture and dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1000        \n",
    "learning_rate = 0.001\n",
    "num_epochs = 500\n",
    "test_data_size = 0.2            # Range 0-1. You may increase or decrease the recommended testing data size by updating this variable\n",
    "hidden_size = 5               # This represents the middle layer of the neural network. You may manually play around with the model architecture by adding more layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's initialize our model with the help of helper functions defined previously. You would also notice the `criterion` and `optimizer` variables that work differently for different tasks. Feel free to play around with them. \n",
    "\n",
    "For more information on loss functions and optimizers, visit:  \n",
    "- https://pytorch.org/docs/stable/nn.html#loss-functions     \n",
    "- https://pytorch.org/docs/stable/optim.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MyModel(\n",
       "  (conv1_1): Conv1d(20, 10, kernel_size=(3,), stride=(1,))\n",
       "  (maxpool): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (fc1): Linear(in_features=5, out_features=7, bias=True)\n",
       "  (fc2): Linear(in_features=7, out_features=3, bias=True)\n",
       "  (fc3): Linear(in_features=3, out_features=3, bias=True)\n",
       "  (relu): LeakyReLU(negative_slope=0.01)\n",
       ")"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data loading calls to class and functions\n",
    "dataset = MyDataset(data_normalized)\n",
    "\n",
    "train_dataset, test_dataset = train_test_split(dataset, test_size=test_data_size, shuffle=False)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Initialzing the model with inputs\n",
    "input_size = len(dataset.features[0])\n",
    "output_size = len(dataset.labels[0])\n",
    "\n",
    "model = MyModel(input_size, hidden_size, output_size, batch_size)\n",
    "# Try out different loss functions and optimizers to see what works with different tasks. \n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)     \n",
    "\n",
    "\"\"\"\n",
    "    If you have GPU resource available, the training process will be faster!\n",
    "    It's okay if you dont have a GPU. The code works without one as well. \n",
    "\"\"\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Model Training & Evaluation\n",
    "\n",
    "Let's train our data using the defined neural network. The notebook implements the training loop, where batches of data are fed into the model iteratively. During training, the model learns to optimize its parameters to minimize the defined loss function through backpropagation. Training hyperparameters, such as learning rate, batch size, and number of epochs, can be fine-tuned to achieve optimal performance.\n",
    "\n",
    "Following training, you will notice the evaluation block that evaluates the neural network's performance on a separate test dataset (not included in training) to assess its performance. \n",
    "\n",
    "Lastly, the `losses` dictionary is populated to visualize important metrics later in the notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1000, 20])\n",
      "torch.Size([1, 1000, 20])\n",
      "torch.Size([1, 20, 1000])\n",
      "shape:  torch.Size([1, 4990])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (1x4990 and 5x7)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/Users/affanbinusman/Dropbox (ASU)/IRL-Lab/P&G/p_and_g_hackathon/scripts/training_advanced.ipynb Cell 17\u001b[0m in \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/affanbinusman/Dropbox%20%28ASU%29/IRL-Lab/P%26G/p_and_g_hackathon/scripts/training_advanced.ipynb#X23sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m \u001b[39mprint\u001b[39m(inputs\u001b[39m.\u001b[39mshape)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/affanbinusman/Dropbox%20%28ASU%29/IRL-Lab/P%26G/p_and_g_hackathon/scripts/training_advanced.ipynb#X23sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m \u001b[39m# exit()\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/affanbinusman/Dropbox%20%28ASU%29/IRL-Lab/P%26G/p_and_g_hackathon/scripts/training_advanced.ipynb#X23sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m outputs \u001b[39m=\u001b[39m model(inputs)                 \u001b[39m# Calculates the output\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/affanbinusman/Dropbox%20%28ASU%29/IRL-Lab/P%26G/p_and_g_hackathon/scripts/training_advanced.ipynb#X23sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m loss \u001b[39m=\u001b[39m criterion(outputs, labels)       \u001b[39m# Finds loss as per the criteria defined\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/affanbinusman/Dropbox%20%28ASU%29/IRL-Lab/P%26G/p_and_g_hackathon/scripts/training_advanced.ipynb#X23sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m loss\u001b[39m.\u001b[39mbackward()                         \u001b[39m# Back propogation of loss\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;32m/Users/affanbinusman/Dropbox (ASU)/IRL-Lab/P&G/p_and_g_hackathon/scripts/training_advanced.ipynb Cell 17\u001b[0m in \u001b[0;36m6\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/affanbinusman/Dropbox%20%28ASU%29/IRL-Lab/P%26G/p_and_g_hackathon/scripts/training_advanced.ipynb#X23sZmlsZQ%3D%3D?line=59'>60</a>\u001b[0m x \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mview(x\u001b[39m.\u001b[39msize(\u001b[39m0\u001b[39m), \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/affanbinusman/Dropbox%20%28ASU%29/IRL-Lab/P%26G/p_and_g_hackathon/scripts/training_advanced.ipynb#X23sZmlsZQ%3D%3D?line=61'>62</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mshape: \u001b[39m\u001b[39m\"\u001b[39m, x\u001b[39m.\u001b[39mshape)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/affanbinusman/Dropbox%20%28ASU%29/IRL-Lab/P%26G/p_and_g_hackathon/scripts/training_advanced.ipynb#X23sZmlsZQ%3D%3D?line=62'>63</a>\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfc1(x)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/affanbinusman/Dropbox%20%28ASU%29/IRL-Lab/P%26G/p_and_g_hackathon/scripts/training_advanced.ipynb#X23sZmlsZQ%3D%3D?line=63'>64</a>\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrelu(x)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/affanbinusman/Dropbox%20%28ASU%29/IRL-Lab/P%26G/p_and_g_hackathon/scripts/training_advanced.ipynb#X23sZmlsZQ%3D%3D?line=64'>65</a>\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfc2(x)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (1x4990 and 5x7)"
     ]
    }
   ],
   "source": [
    "# Storing data for visually observing the losses\n",
    "losses = {\"training\" : [], \n",
    "          \"evaluation\" : [], \n",
    "          \"labels\" : [], \n",
    "          \"outputs\" : [],\n",
    "          \"labels_t\" : [], \n",
    "          \"outputs_t\" : []\n",
    "          }\n",
    "\n",
    "# Training & Evaluation Porcess\n",
    "patience = 15                      # Patience based stopping criteria. You may also play around with this number for early or delayed stopping of the model from over-fitting\n",
    "best_loss = float('inf')\n",
    "num_epochs_without_improvement = 0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    all_outputs_training = []\n",
    "    all_labels_training = []\n",
    "    model.train(True)\n",
    "    running_loss = 0.0                          # To calculates the losses in training for each epoch\n",
    "    for inputs, labels in train_loader:\n",
    "        # Transfers data to GPU/CPU\n",
    "        inputs = inputs.to(device)              \n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()                   # Zeros the optimizer before generating output\n",
    "        print(inputs.shape)\n",
    "        inputs = inputs.unsqueeze(0) \n",
    "        print(inputs.shape)\n",
    "        inputs = torch.swapdims(inputs, 1, 2)\n",
    "        print(inputs.shape)\n",
    "        # exit()\n",
    "        outputs = model(inputs)                 # Calculates the output\n",
    "        loss = criterion(outputs, labels)       # Finds loss as per the criteria defined\n",
    "        loss.backward()                         # Back propogation of loss\n",
    "        optimizer.step()                        # Updates parameters based on gradients computed duing back propogation\n",
    "        \n",
    "        running_loss += loss.item()             # Calculates loss over the training\n",
    "\n",
    "        all_outputs_training.append(outputs.detach().numpy())  # Append outputs to the list\n",
    "        all_labels_training.append(labels.detach().numpy())    # Append labels to the list\n",
    "    \n",
    "    training_loss = running_loss/len(train_loader)\n",
    "\n",
    "    \"\"\"\n",
    "    Evaluating the model that has been trained (so far). \n",
    "    You would notice similar steps as during the training process. The lack of a few lines of code is because we \n",
    "    are evaluating the model here and not training it.\n",
    "    \"\"\"\n",
    "    model.train(False)\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    all_outputs = []\n",
    "    all_labels = []\n",
    "\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            inputs = inputs.unsqueeze(0) \n",
    "            inputs = torch.swapdims(inputs, 1, 2)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            all_outputs.append(outputs.cpu().numpy())  \n",
    "            all_labels.append(labels.cpu().numpy())    \n",
    "                \n",
    "    mean_loss = total_loss / len(test_loader)\n",
    "\n",
    "    if mean_loss < best_loss:\n",
    "        best_loss = mean_loss\n",
    "        num_epochs_without_improvement = 0\n",
    "    else:\n",
    "        num_epochs_without_improvement += 1\n",
    "        if num_epochs_without_improvement == patience:\n",
    "            print(\"Early stopping triggered. Stopping training.\")\n",
    "            break\n",
    "    \n",
    "    # Recording the data values for\n",
    "    losses[\"training\"].append(training_loss)\n",
    "    losses[\"evaluation\"].append(mean_loss)\n",
    "    losses[\"outputs\"] = np.concatenate(all_outputs)\n",
    "    losses[\"labels\"] = np.concatenate(all_labels)\n",
    "    \n",
    "    losses[\"outputs_t\"] = np.concatenate(all_outputs_training)\n",
    "    losses[\"labels_t\"] = np.concatenate(all_labels_training)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Training Loss: {training_loss}, Smooth L1 Loss: {mean_loss}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Performance Analysis & Visualization\n",
    "\n",
    "The model's training and evaluation losses over an epochs curve help to analyze its learning progress and detect signs of overfitting or underfitting. Analyzing these curves aids in fine-tuning the model's architecture or regularization techniques to achieve a balance between accuracy and generalization.\n",
    "\n",
    "Since we will be using the neural networks to estimate the X, Y & Z coordinates, a 3D visualization represents the outputs and actual labels to gain a deeper understanding of the model's performance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lossPlot(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactive_output_visualization(losses[\"labels\"], duration=4, randomseed=False, output=True, output_data=losses[\"outputs\"])\n",
    "interactive_output_visualization(losses[\"labels_t\"], duration=4, randomseed=False, output=True, output_data=losses[\"outputs_t\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove later \\\\ For manual observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(losses[\"outputs_t\"])\n",
    "print()\n",
    "print(losses[\"labels_t\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(losses[\"outputs\"])\n",
    "print()\n",
    "print(losses[\"labels\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
